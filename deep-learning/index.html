<!doctype html>
<html lang="en">
  <head>
    <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="shortcut icon" href="/images/favicon.png" />

<title>Deep Learning&nbsp;|&nbsp; :)</title>
<meta
  name="title"
  content="Deep Learning"
/>
<meta
  name="description"
  content="Day 1 What is Neural Network?
Neuron: holds a number between 0 and 1. The number is also called &ldquo;Activation&rdquo;. Network: multiple layers of neurons connected together. A layer is a series of neurons. Each layer&rsquo;s output affect the neurons of the next layer.
Why the layers?
Each layer construct some parts of information for the next layer until the output layer. Each layer can be represented as a vector. Each neuron in a layer has a weight that connects to the next layer&rsquo;s neuron."
/>
<meta
  name="keywords"
  content=""
/>

  <meta name="author" content="Lee Wei" />




<meta property="og:title" content="Deep Learning" />
<meta property="og:description" content="Day 1 What is Neural Network?
Neuron: holds a number between 0 and 1. The number is also called &ldquo;Activation&rdquo;. Network: multiple layers of neurons connected together. A layer is a series of neurons. Each layer&rsquo;s output affect the neurons of the next layer.
Why the layers?
Each layer construct some parts of information for the next layer until the output layer. Each layer can be represented as a vector. Each neuron in a layer has a weight that connects to the next layer&rsquo;s neuron." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://leewei.co/deep-learning/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2024-09-21T00:20:31-06:00" />
<meta property="article:modified_time" content="2024-09-21T00:20:31-06:00" />




<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Deep Learning"/>
<meta name="twitter:description" content="Day 1 What is Neural Network?
Neuron: holds a number between 0 and 1. The number is also called &ldquo;Activation&rdquo;. Network: multiple layers of neurons connected together. A layer is a series of neurons. Each layer&rsquo;s output affect the neurons of the next layer.
Why the layers?
Each layer construct some parts of information for the next layer until the output layer. Each layer can be represented as a vector. Each neuron in a layer has a weight that connects to the next layer&rsquo;s neuron."/>




<meta itemprop="name" content="Deep Learning">
<meta itemprop="description" content="Day 1 What is Neural Network?
Neuron: holds a number between 0 and 1. The number is also called &ldquo;Activation&rdquo;. Network: multiple layers of neurons connected together. A layer is a series of neurons. Each layer&rsquo;s output affect the neurons of the next layer.
Why the layers?
Each layer construct some parts of information for the next layer until the output layer. Each layer can be represented as a vector. Each neuron in a layer has a weight that connects to the next layer&rsquo;s neuron."><meta itemprop="datePublished" content="2024-09-21T00:20:31-06:00" />
<meta itemprop="dateModified" content="2024-09-21T00:20:31-06:00" />
<meta itemprop="wordCount" content="346">
<meta itemprop="keywords" content="" />
<meta name="referrer" content="no-referrer-when-downgrade" />

    
    <link href="/simple.min.css" rel="stylesheet" />

    
    <link href="/style.min.css" rel="stylesheet" />

    

    
</head>

  <body>
    <header>
      <nav>
  <a
    href="/"
    
    >Home</a
  >

  <a
    href="/blog/"
    
    >Blog</a
  >


  <a href="/index.xml">
    <svg xmlns="http://www.w3.org/2000/svg" class="icon" viewBox="0 0 448 512">
      
      <path
        d="M0 64C0 46.3 14.3 32 32 32c229.8 0 416 186.2 416 416c0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96C14.3 96 0 81.7 0 64zM0 416a64 64 0 1 1 128 0A64 64 0 1 1 0 416zM32 160c159.1 0 288 128.9 288 288c0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224c-17.7 0-32-14.3-32-32s14.3-32 32-32z"
      />
    </svg>
    RSS
  </a>

</nav>

<h1>Deep Learning</h1>


    </header>
    <main>
      
  
    
      
      <p>
        <i>
          <time datetime="2024-09-21" pubdate>
            2024-09-21
          </time>
        </i>
      </p>
    
  
  
  <content>
    <h3 id="day-1">Day 1</h3>
<p>What is Neural Network?</p>
<ul>
<li>Neuron: holds a number between 0 and 1. The number is also called &ldquo;Activation&rdquo;.</li>
<li>Network: multiple layers of neurons connected together.</li>
</ul>
<p>A layer is a series of neurons. Each layer&rsquo;s output affect the neurons of the next layer.</p>
<p>Why the layers?</p>
<ul>
<li>Each layer construct some parts of information for the next layer until the output layer.</li>
<li>Each layer can be represented as a vector.</li>
</ul>
<p>Each neuron in a layer has a weight that connects to the next layer&rsquo;s neuron.
This weight can be seen as a parameter that help detect a certain pattern of our input.</p>
<p>A weighted sum could be any number, but we want this sum value to fit between 0 and 1.
We can utilize a Sigmoid function(old school) or Rectified linear unit.</p>
<p>Bias for inactivity, which can be subtracted to the weighted sum before inputing to Sigmoid or ReLU.</p>
<p><strong>Learning: finding the right weights and biases.</strong></p>
<h3 id="day-2">Day 2</h3>
<p>What is Gradient descent?</p>
<ul>
<li>Finding a minimum of a certain function.</li>
</ul>
<p>Cost function</p>
<ul>
<li>Find the difference between output and the desired result.</li>
<li>If cost is small, then the model produces result that is closed to the desired result.</li>
<li>Input: weights and biases, Output: 1 number(the cost).</li>
</ul>
<p>Gradient, the direction of steepest increase. The opposite of Gradient is the steepest decrease.
The learning process is to adjust the weights to get the minimum cost.</p>
<p>Local minimum is relatively easier to find than Global minimum.</p>
<p><strong>Network Learning: minimizing the cost function.</strong></p>
<h3 id="day-3">Day 3</h3>
<p>What is backpropagation?
An algorithm for determining a single training example for changing the weights in the previous layers.
Which weight changes can rapidly decrease the cost? Some weight changes have bigger affect on the desired output.</p>
<p>A true gradient descent will involve calculating all the data set, which may take long to compute.
Solution: Mini-batches can divide data set into multiple batches and calculate each batch&rsquo;s gradient descent step.
After recursively applying each gradient descent step, we will eventually get the local minimum of our data set.</p>
<p><strong>Backpropagation: tune weights to lean towards the desired output.</strong></p>

  </content>
  <p>
    
  </p>

    </main>
    <footer>
      
  <span>© 2024 Lee Wei</span>


  <span>
    |
    Made with
    <a href="https://github.com/maolonglong/hugo-simple/">Hugo ʕ•ᴥ•ʔ Simple</a>
  </span>


    </footer>

    
</body>
</html>
